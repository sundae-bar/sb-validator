# ============================================================================
# Sundae Bar Validator Configuration
# ============================================================================
# Copy this file to .env and update with your actual values
# cp env.example .env

# ============================================================================
# Required Configuration
# ============================================================================

# Required: Your Bittensor validator hotkey mnemonic (12-word phrase)
# This is the same mnemonic you use for your Bittensor validator on subnet 121
# Do NOT generate a new one - use your existing validator hotkey mnemonic
VALIDATOR_MNEMONIC=word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12

# Required: Coordinator API URL
# Can be base URL (e.g., http://localhost:3002) or full path (e.g., http://localhost:3002/api/v2/validators)
API_URL=https://api.sundaebar.ai/api/v2/validators

# Required: Letta server URL
# For local server: http://localhost:8283 or http://host.docker.internal:8283 (Docker)
# For remote server: https://your-letta-server.com
LETTA_BASE_URL=http://localhost:8283

# ============================================================================
# Optional: Validator Settings
# ============================================================================

# Optional: Validator display name
DISPLAY_NAME=My Validator

# Optional: Poll interval in seconds (default: 60)
POLL_INTERVAL=60

# Optional: Heartbeat interval in seconds (default: 60)
HEARTBEAT_INTERVAL=60

# Optional: Max retries for failed requests (default: 3)
MAX_RETRIES=3

# Optional: Retry delay in milliseconds (default: 10000)
RETRY_DELAY=10000

# Optional: Log level (default: info)
# Options: trace, debug, info, warn, error, fatal
LOG_LEVEL=info

# Optional: Working directory for task files (default: /tmp/validator-work)
WORK_DIR=/tmp/validator-work

# Optional: Maximum number of tasks to process concurrently (default: 1)
MAX_CONCURRENT_TASKS=1

# Optional: HTTP server port for health checks (default: 8080)
SERVER_PORT=8080

# Optional: Set to 1 to keep task files after processing (for debugging)
# KEEP_TASK_FILES=1

# ============================================================================
# Optional: Evaluation Settings
# ============================================================================

# Optional: Maximum number of agent steps/tool calls per evaluation sample (default: 10)
MAX_STEPS=10

# Optional: Maximum time to wait for file embeddings to complete in minutes (default: 30)
LETTA_EMBEDDING_WAIT_MINUTES=30

# Optional: Python command to use for running letta-evals (default: python3)
LETTA_EVALS_PYTHON=python3

# Optional: Python module to use for letta-evals CLI (default: letta_evals.cli)
LETTA_EVALS_MODULE=letta_evals.cli

# Optional: GitHub personal access token for authenticated API requests (increases rate limits)
# Get from: https://github.com/settings/tokens
# GITHUB_TOKEN=ghp_your_token_here

# ============================================================================
# Optional: Bittensor Weights Configuration
# ============================================================================

# Optional: Interval for fetching and submitting Bittensor weights in minutes (default: 30)
BITTENSOR_WEIGHTS_INTERVAL_MINUTES=30

# Optional: Set to true to disable on-chain weight submission (still fetches and logs) (default: false)
BITTENSOR_WEIGHTS_DISABLED=false

# ============================================================================
# Model Provider API Keys
# ============================================================================
# These keys are used for graders when evaluating agent responses.
# The models are specified in suite.yaml with the 'provider' field.
# 
# Provide at least ONE key for the models you plan to use.
# You can provide multiple keys to support different providers.
#
# Note: For agent execution (models in .af files), API keys are configured
# on the Letta server side, not here.

# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
# Format: sk-...
# OPENAI_API_KEY=sk-your-api-key-here

# Anthropic API Key
# Get from: https://console.anthropic.com/settings/keys
# Format: sk-ant-...
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Google API Key
# Get from: https://aistudio.google.com/app/apikey
# Format: AIza...
# GOOGLE_API_KEY=AIza-your-google-api-key-here

# OpenRouter API Key
# Get from: https://openrouter.ai/keys
# Format: sk-or-...
# OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here

# Together AI API Key (use either TOGETHER_API_KEY or TOGETHERAI_API_KEY)
# Get from: https://together.ai/
# Format: (varies)
# TOGETHER_API_KEY=your-together-api-key-here

# Together AI API Key (alternative to TOGETHER_API_KEY)
# TOGETHERAI_API_KEY=your-together-api-key-here

# ============================================================================
# Deprecated/Alternative Variables
# ============================================================================

# Deprecated: Use LETTA_BASE_URL instead
# LETTA_URL=http://localhost:8283
